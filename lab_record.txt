4 dropout 0.25, all kernel size 3, lr decay
New Learn Rate: 1.0000000000000002e-06!
[76/1000] 8s, Loss: 0.1514, Val-Loss: 0.1683, Best Val-Loss: 0.1635, Val-F2: 0.84
[77/1000] 8s, Loss: 0.1520, Val-Loss: 0.1684, Best Val-Loss: 0.1635, Val-F2: 0.84
[78/1000] 8s, Loss: 0.1514, Val-Loss: 0.1681, Best Val-Loss: 0.1635, Val-F2: 0.84
Early Stop in Epoch: 79, Best Val-Loss: 0.163452, Best F2: 0.849780

2 dropout 0.5, 2 dropout 0.25, all kernel size 3, lr decay
New Learn Rate: 1.0000000000000002e-06!
[51/1000] 8s, Loss: 0.1680, Val-Loss: 0.1815, Best Val-Loss: 0.1801, Val-F2: 0.82
[52/1000] 8s, Loss: 0.1700, Val-Loss: 0.1823, Best Val-Loss: 0.1801, Val-F2: 0.82
[53/1000] 8s, Loss: 0.1715, Val-Loss: 0.1820, Best Val-Loss: 0.1801, Val-F2: 0.82
Early Stop in Epoch: 54, Best Val-Loss: 0.180122, Best F2: 0.830061

 2 dropout 0.25, all kernel size 3, lr decay
 New Learn Rate: 1.0000000000000002e-07!
[76/1000] 8s, Loss: 0.1471, Val-Loss: 0.1747, Best Val-Loss: 0.1723, Val-F2: 0.83
[77/1000] 8s, Loss: 0.1468, Val-Loss: 0.1740, Best Val-Loss: 0.1723, Val-F2: 0.83
[78/1000] 8s, Loss: 0.1472, Val-Loss: 0.1741, Best Val-Loss: 0.1723, Val-F2: 0.83
Early Stop in Epoch: 79, Best Val-Loss: 0.172291, Best F2: 0.839359

4 dropout 0.25, 1 kernel size 5, 3 kernel size 3, lr decay & jump out 1e-5
New Learn Rate: 1.0000000000000002e-06!
[81/1000] 9s, Loss: 0.1586, Val-Loss: 0.1653, Best Val-Loss: 0.1650, Val-F2: 0.84
[82/1000] 9s, Loss: 0.1575, Val-Loss: 0.1653, Best Val-Loss: 0.1650, Val-F2: 0.83
[83/1000] 9s, Loss: 0.1584, Val-Loss: 0.1652, Best Val-Loss: 0.1650, Val-F2: 0.83
Early Stop in Epoch: 84, Best Val-Loss: 0.165002, Best F2: 0.845297

4 dropout 0.25, 1 kernel size 5, 3 kernel size 3, lr decay & jump out 1e-4
New Learn Rate: 0.0001!
[119/1000] 9s, Loss: 0.1584, Val-Loss: 0.2175, Best Val-Loss: 0.1646, Val-F2: 0.80
[120/1000] 9s, Loss: 0.1522, Val-Loss: 0.1752, Best Val-Loss: 0.1646, Val-F2: 0.83
[121/1000] 9s, Loss: 0.1522, Val-Loss: 0.1699, Best Val-Loss: 0.1646, Val-F2: 0.83
Early Stop in Epoch: 122, Best Val-Loss: 0.164583, Best F2: 0.852326

0 dropout, 1 kernel size 5, 3 kernel size 3, lr decay
New Learn Rate: 1.0000000000000002e-06!
[62/1000] 9s, Loss: 0.1392, Val-Loss: 0.1723, Best Val-Loss: 0.1657, Val-F2: 0.84
[63/1000] 9s, Loss: 0.1397, Val-Loss: 0.1723, Best Val-Loss: 0.1657, Val-F2: 0.84
[64/1000] 9s, Loss: 0.1378, Val-Loss: 0.1713, Best Val-Loss: 0.1657, Val-F2: 0.85
Early Stop in Epoch: 65, Best Val-Loss: 0.165691, Best F2: 0.853156

0 dropout, 1 kernel size 5, 3 kernel size 3, lr decay, transforms.Normalize
New Learn Rate: 1.0000000000000002e-06!
[52/1000] 9s, Loss: 0.1478, Val-Loss: 0.1687, Best Val-Loss: 0.1638, Val-F2: 0.84
[53/1000] 9s, Loss: 0.1470, Val-Loss: 0.1681, Best Val-Loss: 0.1638, Val-F2: 0.84
[54/1000] 9s, Loss: 0.1481, Val-Loss: 0.1678, Best Val-Loss: 0.1638, Val-F2: 0.84
Early Stop in Epoch: 55, Best Val-Loss: 0.163838, Best F2: 0.853148

0 dropout, 1 kernel size 5, 3 kernel size 3, lr decay, transforms.Normalize weights 11 .8, 6 1.
New Learn Rate: 1.0000000000000002e-06!
[64/1000] 9s, Loss: 0.1131, Val-Loss: 0.1395, Best Val-Loss: 0.1356, Val-F2: 0.84
[65/1000] 9s, Loss: 0.1148, Val-Loss: 0.1397, Best Val-Loss: 0.1356, Val-F2: 0.84
[66/1000] 9s, Loss: 0.1134, Val-Loss: 0.1402, Best Val-Loss: 0.1356, Val-F2: 0.84
Early Stop in Epoch: 67, Best Val-Loss: 0.135608, Best F2: 0.858180

0 dropout, 1 kernel size 5, 3 kernel size 3, lr decay, transforms.Normalize
weights = torch.Tensor([.6, .8, .8, .8, .6, .8, .8, .8, .8, .8, .8, 1., 1., 1., 1., 1., 1.])
New Learn Rate: 1.0000000000000002e-06!
[60/1000] 9s, Loss: 0.1150, Val-Loss: 0.1307, Best Val-Loss: 0.1271, Val-F2: 0.85
[61/1000] 9s, Loss: 0.1163, Val-Loss: 0.1303, Best Val-Loss: 0.1271, Val-F2: 0.85
[62/1000] 9s, Loss: 0.1133, Val-Loss: 0.1300, Best Val-Loss: 0.1271, Val-F2: 0.85
Early Stop in Epoch: 63, Best Val-Loss: 0.127099, Best F2: 0.848436

先缩小再处理，加入上下翻转
New Learn Rate: 1e-05!
[51/1000] 10s, Loss: 0.0427, Val-Loss: 0.1813, Best Val-Loss: 0.1687, Val-F2: 0.84
[52/1000] 9s, Loss: 0.0424, Val-Loss: 0.1811, Best Val-Loss: 0.1687, Val-F2: 0.84
[53/1000] 9s, Loss: 0.0420, Val-Loss: 0.1812, Best Val-Loss: 0.1687, Val-F2: 0.84
[54/1000] 9s, Loss: 0.0412, Val-Loss: 0.1810, Best Val-Loss: 0.1687, Val-F2: 0.84
Early Stop in Epoch: 55, Best Val-Loss: 0.168723, Best F2: 0.856480

不用NB, 只用dropout
New Learn Rate: 1.0000000000000002e-06!
[74/1000] 9s, Loss: 0.1218, Val-Loss: 0.1761, Best Val-Loss: 0.1751, Val-F2: 0.82
[75/1000] 9s, Loss: 0.1226, Val-Loss: 0.1762, Best Val-Loss: 0.1751, Val-F2: 0.82
[76/1000] 9s, Loss: 0.1207, Val-Loss: 0.1759, Best Val-Loss: 0.1751, Val-F2: 0.82
[77/1000] 9s, Loss: 0.1206, Val-Loss: 0.1759, Best Val-Loss: 0.1751, Val-F2: 0.82
Early Stop in Epoch: 78, Best Val-Loss: 0.175095, Best F2: 0.844616

同时使用NB和dropout
New Learn Rate: 1.0000000000000002e-06!
[64/1000] 10s, Loss: 0.0813, Val-Loss: 0.1590, Best Val-Loss: 0.1556, Val-F2: 0.85
[65/1000] 10s, Loss: 0.0830, Val-Loss: 0.1591, Best Val-Loss: 0.1556, Val-F2: 0.85
[66/1000] 10s, Loss: 0.0818, Val-Loss: 0.1589, Best Val-Loss: 0.1556, Val-F2: 0.85
[67/1000] 10s, Loss: 0.0829, Val-Loss: 0.1592, Best Val-Loss: 0.1556, Val-F2: 0.85
Early Stop in Epoch: 68, Best Val-Loss: 0.155614, Best F2: 0.861291

将一个dropout的参数由0.25改到0.5
New Learn Rate: 1.0000000000000002e-06!
[68/1000] 9s, Loss: 0.0952, Val-Loss: 0.1678, Best Val-Loss: 0.1655, Val-F2: 0.84
[69/1000] 9s, Loss: 0.0921, Val-Loss: 0.1673, Best Val-Loss: 0.1655, Val-F2: 0.84
[70/1000] 10s, Loss: 0.0934, Val-Loss: 0.1672, Best Val-Loss: 0.1655, Val-F2: 0.84
[71/1000] 10s, Loss: 0.0925, Val-Loss: 0.1672, Best Val-Loss: 0.1655, Val-F2: 0.84
Early Stop in Epoch: 72, Best Val-Loss: 0.165459, Best F2: 0.848326

dropout的参数全设置为0.25
New Learn Rate: 1.0000000000000002e-06!
[58/1000] 10s, Loss: 0.1023, Val-Loss: 0.1671, Best Val-Loss: 0.1644, Val-F2: 0.84
[59/1000] 10s, Loss: 0.1000, Val-Loss: 0.1673, Best Val-Loss: 0.1644, Val-F2: 0.84
[60/1000] 10s, Loss: 0.1018, Val-Loss: 0.1667, Best Val-Loss: 0.1644, Val-F2: 0.84
[61/1000] 10s, Loss: 0.0995, Val-Loss: 0.1667, Best Val-Loss: 0.1644, Val-F2: 0.84
Early Stop in Epoch: 62, Best Val-Loss: 0.164387, Best F2: 0.846353

./alexnet-703-1.pth
好了，取消1000数据的限制, 55次迭代出现最好成绩
New Learn Rate: 1.0000000000000002e-06!
[77/1000] 163s, Loss: 0.0637, Val-Loss: 0.1152, Best Val-Loss: 0.1144, Val-F2: 0.90
[78/1000] 278s, Loss: 0.0648, Val-Loss: 0.1151, Best Val-Loss: 0.1144, Val-F2: 0.90
[79/1000] 172s, Loss: 0.0638, Val-Loss: 0.1151, Best Val-Loss: 0.1144, Val-F2: 0.90
[80/1000] 163s, Loss: 0.0640, Val-Loss: 0.1153, Best Val-Loss: 0.1144, Val-F2: 0.90
Early Stop in Epoch: 81, Best Val-Loss: 0.114385, Best F2: 0.903251

./alexnet-703-2.pth
用64*64的分辨率，batchsize=256
New Learn Rate: 1.0000000000000002e-06!
[69/1000] 93s, Loss: 0.0943, Val-Loss: 0.1062, Best Val-Loss: 0.1061, Val-F2: 0.90
[70/1000] 94s, Loss: 0.0941, Val-Loss: 0.1061, Best Val-Loss: 0.1061, Val-F2: 0.90
[71/1000] 95s, Loss: 0.0939, Val-Loss: 0.1061, Best Val-Loss: 0.1061, Val-F2: 0.90
[72/1000] 94s, Loss: 0.0950, Val-Loss: 0.1062, Best Val-Loss: 0.1061, Val-F2: 0.90
[73/1000] 94s, Loss: 0.0944, Val-Loss: 0.1061, Best Val-Loss: 0.1061, Val-F2: 0.90
[74/1000] 94s, Loss: 0.0946, Val-Loss: 0.1061, Best Val-Loss: 0.1061, Val-F2: 0.90
[75/1000] 94s, Loss: 0.0950, Val-Loss: 0.1061, Best Val-Loss: 0.1061, Val-F2: 0.90
[76/1000] 96s, Loss: 0.0939, Val-Loss: 0.1061, Best Val-Loss: 0.1061, Val-F2: 0.90
New Learn Rate: 1.0000000000000002e-07!
Early Stop in Epoch: 77, Best Val-Loss: 0.106072, Best F2: 0.907623

./alexnet-705-1.pth
不用dropout
New Learn Rate: 0.0001!
[32/1000] 162s, Loss: 0.0683, Val-Loss: 0.1279, Best Val-Loss: 0.1198, Val-F2: 0.88
[33/1000] 162s, Loss: 0.0597, Val-Loss: 0.1236, Best Val-Loss: 0.1198, Val-F2: 0.89
[34/1000] 162s, Loss: 0.0567, Val-Loss: 0.1228, Best Val-Loss: 0.1198, Val-F2: 0.89
[35/1000] 162s, Loss: 0.0551, Val-Loss: 0.1234, Best Val-Loss: 0.1198, Val-F2: 0.89
[36/1000] 162s, Loss: 0.0525, Val-Loss: 0.1237, Best Val-Loss: 0.1198, Val-F2: 0.89
[37/1000] 162s, Loss: 0.0517, Val-Loss: 0.1245, Best Val-Loss: 0.1198, Val-F2: 0.89
[38/1000] 162s, Loss: 0.0514, Val-Loss: 0.1253, Best Val-Loss: 0.1198, Val-F2: 0.89
[39/1000] 162s, Loss: 0.0499, Val-Loss: 0.1247, Best Val-Loss: 0.1198, Val-F2: 0.89
New Learn Rate: 1e-05!
Early Stop in Epoch: 40, Best Val-Loss: 0.119806, Best F2: 0.892933

./alexnet-705-2.pth
恢复dropout. 用上权重weights = torch.Tensor([.6, .8, .8, .8, .6, .8, .8, .8, .8, .8, .8, 1., 1., 1., 1., 1., 1.])
New Learn Rate: 1e-05!
[60/1000] 168s, Loss: 0.0561, Val-Loss: 0.0892, Best Val-Loss: 0.0885, Val-F2: 0.90
[61/1000] 168s, Loss: 0.0549, Val-Loss: 0.0890, Best Val-Loss: 0.0885, Val-F2: 0.90
[62/1000] 168s, Loss: 0.0555, Val-Loss: 0.0892, Best Val-Loss: 0.0885, Val-F2: 0.90
[63/1000] 168s, Loss: 0.0550, Val-Loss: 0.0893, Best Val-Loss: 0.0885, Val-F2: 0.90
[64/1000] 168s, Loss: 0.0547, Val-Loss: 0.0892, Best Val-Loss: 0.0885, Val-F2: 0.90
[65/1000] 168s, Loss: 0.0549, Val-Loss: 0.0894, Best Val-Loss: 0.0885, Val-F2: 0.90
[66/1000] 168s, Loss: 0.0547, Val-Loss: 0.0893, Best Val-Loss: 0.0885, Val-F2: 0.90
[67/1000] 168s, Loss: 0.0545, Val-Loss: 0.0894, Best Val-Loss: 0.0885, Val-F2: 0.90
New Learn Rate: 1.0000000000000002e-06!
Early Stop in Epoch: 68, Best Val-Loss: 0.088525, Best F2: 0.906084

nmd, 设不设损失函数的权重，设置怎样的权重，几乎没有影响
./alexnet-706-1.pth
weights = torch.Tensor([ 0.01618724,  0.06338461,  0.17064727,  0.22031387,  0.0122687 ,
        0.03737196,  0.05702338,  0.0621017 ,  0.10280002,  0.12574745,
        0.5339161 ,  1.35363436,  1.35762738,  1.38625205,  2.2020846 ,
        4.60235682,  4.69628247])
New Learn Rate: 1e-05!
[46/1000] 162s, Loss: 0.0258, Val-Loss: 0.0315, Best Val-Loss: 0.0311, Val-F2: 0.85
[47/1000] 161s, Loss: 0.0257, Val-Loss: 0.0315, Best Val-Loss: 0.0311, Val-F2: 0.85
[48/1000] 160s, Loss: 0.0257, Val-Loss: 0.0314, Best Val-Loss: 0.0311, Val-F2: 0.86
[49/1000] 159s, Loss: 0.0255, Val-Loss: 0.0313, Best Val-Loss: 0.0311, Val-F2: 0.86
[50/1000] 160s, Loss: 0.0255, Val-Loss: 0.0313, Best Val-Loss: 0.0311, Val-F2: 0.86
[51/1000] 159s, Loss: 0.0253, Val-Loss: 0.0313, Best Val-Loss: 0.0311, Val-F2: 0.86
[52/1000] 162s, Loss: 0.0257, Val-Loss: 0.0313, Best Val-Loss: 0.0311, Val-F2: 0.86
[53/1000] 166s, Loss: 0.0251, Val-Loss: 0.0312, Best Val-Loss: 0.0311, Val-F2: 0.86
New Learn Rate: 1.0000000000000002e-06!
Early Stop in Epoch: 54, Best Val-Loss: 0.031142, Best F2: 0.859892

试了试重采样频率probs = [0.5, 0.6, 0.8, 0.8, 0.5, 0.5, 0.6, 0.6, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
New Learn Rate: 1.0000000000000002e-06!
[81/1000] 93s, Loss: 0.1133, Val-Loss: 0.1084, Best Val-Loss: 0.1082, Val-F2: 0.90
[82/1000] 93s, Loss: 0.1148, Val-Loss: 0.1084, Best Val-Loss: 0.1082, Val-F2: 0.90
[83/1000] 93s, Loss: 0.1174, Val-Loss: 0.1097, Best Val-Loss: 0.1082, Val-F2: 0.90
[84/1000] 93s, Loss: 0.1161, Val-Loss: 0.1084, Best Val-Loss: 0.1082, Val-F2: 0.90
[85/1000] 93s, Loss: 0.1153, Val-Loss: 0.1085, Best Val-Loss: 0.1082, Val-F2: 0.90
[86/1000] 93s, Loss: 0.1143, Val-Loss: 0.1084, Best Val-Loss: 0.1082, Val-F2: 0.90
[87/1000] 93s, Loss: 0.1181, Val-Loss: 0.1086, Best Val-Loss: 0.1082, Val-F2: 0.90
[88/1000] 93s, Loss: 0.1163, Val-Loss: 0.1089, Best Val-Loss: 0.1082, Val-F2: 0.90
New Learn Rate: 1.0000000000000002e-07!
Early Stop in Epoch: 89, Best Val-Loss: 0.108198, Best F2: 0.902721

修改了旋转图像0-45度间的随机角度
New Learn Rate: 1.0000000000000002e-06!
2 [77/1000] 93s, Loss: 0.0909, Val-Loss: 0.0906, Best Val-Loss: 0.0902, Val-F2: 0.92
2 [78/1000] 93s, Loss: 0.0898, Val-Loss: 0.0907, Best Val-Loss: 0.0902, Val-F2: 0.92
2 [79/1000] 93s, Loss: 0.0911, Val-Loss: 0.0911, Best Val-Loss: 0.0902, Val-F2: 0.92
2 [80/1000] 93s, Loss: 0.0908, Val-Loss: 0.0904, Best Val-Loss: 0.0902, Val-F2: 0.92
2 [81/1000] 93s, Loss: 0.0912, Val-Loss: 0.0907, Best Val-Loss: 0.0902, Val-F2: 0.92
2 [82/1000] 93s, Loss: 0.0910, Val-Loss: 0.0907, Best Val-Loss: 0.0902, Val-F2: 0.92
2 [83/1000] 93s, Loss: 0.0903, Val-Loss: 0.0906, Best Val-Loss: 0.0902, Val-F2: 0.92
2 [84/1000] 93s, Loss: 0.0916, Val-Loss: 0.0908, Best Val-Loss: 0.0902, Val-F2: 0.92
New Learn Rate: 1.0000000000000002e-07!
Early Stop in Epoch: 85, Best Val-Loss: 0.090189, Best F2: 0.921552